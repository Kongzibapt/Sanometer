{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c97a3b1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6b820db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['M', 56, 'Fr', 'white', 'urban>1 milion', 'plane', 'professional school', 5, 'no', 'N', 'N', 'N', 'Y', 'N'] ['M', 47, 'Fr', 'white', '<100 000', 'hills', 'high school', 7, 'no', 'N', 'N', 'N', 'N', 'N']\n",
      "features : \n",
      " ['sex', 'age', 'country of birth', 'race', 'place of living (aggomeration) ', 'geographie of living place', 'profession (studies)', 'Berg scale (profession)', 'recent change of professional field']\n",
      "features res: \n",
      " ['It is recommended to have a screening test for cervical (uterin) cancer every 3 years with cervical cytology test ', 'It is recommended to have a screening test every 3 years wit cervical cytology test alone', 'it is recommended to have a screening test every 5 years with high-risk human papilloma virus (PV) test alone', 'It is recommended to have a screening stool test every 2 years: the high senzitivity guaiac fecal occult blood test (gFOBT) or fecal immunochemical test (FIT)', 'It is recommended to have a mammography every 2 years']\n",
      "['M', 'M', 'F', 'M', 'F', 'F', 'F', 'F', 'M', 'M', 'F', 'F', 'F', 'M', 'M', 'M', 'F', 'M', 'F', 'F', 'F', 'F', 'M', 'M', 'F', 'F', 'F', 'M', 'M']\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "df = pd.read_excel (r'patient_data.xlsx', sheet_name='Sheet1')\n",
    "raw_datas = df.values.tolist()\n",
    "print(raw_datas[0],raw_datas[1])\n",
    "\n",
    "\n",
    "features_list = list(df.to_dict().keys())[:-5] \n",
    "features_res_list = list(df.to_dict().keys())[-5:] \n",
    "print(\"features : \\n\", features_list)\n",
    "print(\"features res: \\n\", features_res_list)\n",
    "\n",
    "print(df[features_list[0]].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02be5efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['M', 56, 'Fr', 'white', 'urban>1 milion', 'plane', 'professional school', 5, 'no'], ['M', 47, 'Fr', 'white', '<100 000', 'hills', 'high school', 7, 'no'], ['F', 52, 'Fr', 'white', 'urban<1 milion', 'sea', 'bachelor', 3, 'Y'], ['M', 53, 'Fr', 'white', '<100 000', 'plane', 'bachelor', 5, 'Y'], ['F', 34, 'Fr', 'white', '> 1 million ', 'plane', 'master', 3, 'Y'], ['F', 27, 'Fr', 'white', '<100 000', 'hills', 'professional school', 7, 'No'], ['F', 46, 'Fr', 'white', '> 1 million ', 'sea', 'master', 2, 'No'], ['F', 39, 'Fr', 'white', '> 1 million ', 'plane', 'bachelor', 3, 'No'], ['M', 62, 'Fr', 'white', '100 000-1 milion', 'sea', 'professional school', 5, 'Y'], ['M', 28, 'African', 'black', '100 000-1 milion', 'plane', 'bachelor', 3, 'Y'], ['F', 44, 'African', 'black', '> 1 million ', 'sea', 'high school', 6, 'No'], ['F', 48, 'African', 'black', '<100 000', 'sea', 'high school', 5, 'Y'], ['F', 39, 'African', 'black', '100 000-1 milion', 'plane', 'bachelor', 4, 'Y'], ['M', 40, 'Afro-american', 'black', '> 1 million ', 'sea', 'master', 4, 'Y'], ['M', 56, 'Fr', 'white', 'urban>1 milion', 'plane', 'professional school', 5, 'no'], ['M', 47, 'Fr', 'white', '<100 000', 'hills', 'high school', 7, 'no'], ['F', 52, 'Fr', 'white', 'urban<1 milion', 'sea', 'bachelor', 3, 'Y'], ['M', 53, 'Fr', 'white', '<100 000', 'plane', 'bachelor', 5, 'Y'], ['F', 34, 'Fr', 'white', '> 1 million ', 'plane', 'master', 3, 'Y'], ['F', 27, 'Fr', 'white', '<100 000', 'hills', 'professional school', 7, 'No'], ['F', 46, 'Fr', 'white', '> 1 million ', 'sea', 'master', 2, 'No'], ['F', 39, 'Fr', 'white', '> 1 million ', 'plane', 'bachelor', 3, 'No'], ['M', 62, 'Fr', 'white', '100 000-1 milion', 'sea', 'professional school', 5, 'Y'], ['M', 28, 'African', 'black', '100 000-1 milion', 'plane', 'bachelor', 3, 'Y'], ['F', 44, 'African', 'black', '> 1 million ', 'sea', 'high school', 6, 'No'], ['F', 48, 'African', 'black', '<100 000', 'sea', 'high school', 5, 'Y'], ['F', 39, 'African', 'black', '100 000-1 milion', 'plane', 'bachelor', 4, 'Y'], ['M', 40, 'Afro-american', 'black', '> 1 million ', 'sea', 'master', 4, 'Y'], ['M', 45, 'chinese', 'south Asia', '> 1 million ', 'plane', 'professional school', 7, 'Y']]\n",
      "[[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0], [0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0], [1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X=[]\n",
    "y=[]\n",
    "y_element1 = []\n",
    "y_element2 = []\n",
    "y_element3 = []\n",
    "y_element4 = []\n",
    "y_element5 = []\n",
    "\n",
    "poss_list = {}\n",
    "cnt_list = [0]*len(raw_datas[0])\n",
    "\n",
    "for j in range(len(raw_datas)):\n",
    "    X_element = []\n",
    "    \n",
    "    for i in range(len(raw_datas[0])):\n",
    "           \n",
    "        if (i<=len(raw_datas[0])-6):\n",
    "            ##on est dans les features\n",
    "            X_element.append(raw_datas[j][i])\n",
    "    \n",
    "        elif (i==len(raw_datas[0])-1) :\n",
    "            if (raw_datas[j][i]=='Y') :\n",
    "            \n",
    "                y_element5.append(1)\n",
    "            else :\n",
    "                ##par défaut si on a pas de réponse je met 0 comme pour 'N'\n",
    "                y_element5.append(0)\n",
    "        elif (i==len(raw_datas[0])-2) :\n",
    "            if (raw_datas[j][i]=='Y') :\n",
    "            \n",
    "                y_element4.append(1)\n",
    "            else :\n",
    "                ##par défaut si on a pas de réponse je met 0 comme pour 'N'\n",
    "                y_element4.append(0)\n",
    "        elif (i==len(raw_datas[0])-3) :\n",
    "            if (raw_datas[j][i]=='Y') :\n",
    "            \n",
    "                y_element3.append(1)\n",
    "            else :\n",
    "                ##par défaut si on a pas de réponse je met 0 comme pour 'N'\n",
    "                y_element3.append(0)\n",
    "        elif (i==len(raw_datas[0])-4) :\n",
    "            if (raw_datas[j][i]=='Y') :\n",
    "            \n",
    "                y_element2.append(1)\n",
    "            else :\n",
    "                ##par défaut si on a pas de réponse je met 0 comme pour 'N'\n",
    "                y_element2.append(0)\n",
    "        elif (i==len(raw_datas[0])-5) :\n",
    "            if (raw_datas[j][i]=='Y') :\n",
    "            \n",
    "                y_element1.append(1)\n",
    "            else :\n",
    "                ##par défaut si on a pas de réponse je met 0 comme pour 'N'\n",
    "                y_element1.append(0)\n",
    "        \n",
    "    \n",
    "    X.append(X_element)   \n",
    "\n",
    "y.append(y_element1)  \n",
    "y.append(y_element2)\n",
    "y.append(y_element3)\n",
    "y.append(y_element4)\n",
    "y.append(y_element5)\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "011a803d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "dimension = len(X[0])\n",
    "\n",
    "# define two sets of inputs\n",
    "inputA = Input(shape=(32,))\n",
    "inputB = Input(shape=(128,))\n",
    "\n",
    "# the first branch operates on the first input\n",
    "x = Dense(8, activation=\"relu\")(inputA)\n",
    "x = Dense(4, activation=\"relu\")(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "# the second branch opreates on the second input\n",
    "y = Dense(64, activation=\"relu\")(inputB)\n",
    "y = Dense(32, activation=\"relu\")(y)\n",
    "y = Dense(4, activation=\"relu\")(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "\n",
    "# combine the output of the two branches\n",
    "combined = concatenate([x.output, y.output])\n",
    "\n",
    "# apply a FC layer and then a regression prediction on the\n",
    "# combined outputs\n",
    "z = Dense(2, activation=\"relu\")(combined)\n",
    "z = Dense(1, activation=\"linear\")(z)\n",
    "\n",
    "# our model will accept the inputs of the two branches and\n",
    "# then output a single value\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0bb79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd35d570",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 29\n  y sizes: 5\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# fit the keras model on the dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\data_adapter.py:1653\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1649\u001b[0m   msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m sizes: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1650\u001b[0m       label, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m   1651\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(single_data)))\n\u001b[0;32m   1652\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1653\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 29\n  y sizes: 5\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=150, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f5fd40e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\fifid\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fifid\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fifid\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\fifid\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\fifid\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fifid\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 8), found shape=(None, 9)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# make class predictions with the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m (\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\fifid\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\fifid\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\fifid\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\Users\\fifid\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\Users\\fifid\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\fifid\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 8), found shape=(None, 9)\n"
     ]
    }
   ],
   "source": [
    "# make class predictions with the model\n",
    "predictions = (model.predict(X) > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f5bc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
